# UI Upgrade Instructions for app_langgraph.py

## Changes to Make

### 1. Update Metrics Section (Line 371-389)

**REPLACE:**
```python
# === PHáº¦N 1: THá»NG KÃŠ Tá»”NG QUAN (4 METRICS) ===
col1, col2, col3, col4 = st.columns(4)

with col1:
    st.metric("ğŸ“š BÃ i bÃ¡o", len(final_state['final_results']))

with col2:
    quality = final_state['quality_score']
    quality_label = "Xuáº¥t sáº¯c" if quality >= 0.8 else "Tá»‘t" if quality >= 0.6 else "Cháº¥p nháº­n"
    st.metric("â­ Cháº¥t lÆ°á»£ng", f"{quality:.2f}", quality_label)

with col3:
    st.metric("ğŸ”„ Refinement", f"{final_state['refinement_count']}/2")

with col4:
    metadata = final_state.get('metadata', {})
    removed = metadata.get('total_found', 0) - len(final_state['final_results'])
    st.metric("ğŸ—‘ï¸ ÄÃ£ loáº¡i", f"{removed}")
```

**WITH:**
```python
# === PHáº¦N 1: THá»NG KÃŠ Tá»”NG QUAN (5 METRICS) - UPDATED ===
col1, col2, col3, col4, col5 = st.columns(5)

# Get filter statistics
filter_stats = final_state.get('filter_statistics', {})
total_found = filter_stats.get('total_found', 0)
kept_count = len(final_state.get('final_results', []))
discarded_count = filter_stats.get('discarded', 0)
avg_score = filter_stats.get('avg_score', 0.0)
pass_rate = filter_stats.get('pass_rate', 0.0)

with col1:
    st.metric("ğŸ“š Tá»•ng tÃ¬m tháº¥y", total_found)

with col2:
    delta_pct = f"+{pass_rate}%" if pass_rate > 0 else None
    st.metric("âœ… Giá»¯ láº¡i", kept_count, delta=delta_pct)

with col3:
    st.metric("ğŸ—‘ï¸ Lá»c ra", discarded_count)

with col4:
    score_label = "Tá»‘t" if avg_score >= 7 else "Trung bÃ¬nh" if avg_score >= 5 else "Tháº¥p"
    st.metric("â­ Äiá»ƒm TB", f"{avg_score}/10", score_label)

with col5:
    st.metric("ğŸ”„ Refine", f"{final_state['refinement_count']}/2")
```

### 2. Add Literature Synthesis Section (Insert AFTER line 390, BEFORE "LÆ°u Káº¿t quáº£")

**INSERT:**
```python
        st.markdown("---")

        # === NEW: PHáº¦N 2: AI LITERATURE SYNTHESIS ===
        synthesis = final_state.get('synthesis_summary')

        if synthesis:
            st.markdown("## ğŸ§  AI Literature Review")

            with st.expander("ğŸ“– Äá»c tá»•ng quan nghiÃªn cá»©u do AI viáº¿t", expanded=True):
                st.markdown(synthesis)

                # Show synthesis metadata
                synth_meta = final_state.get('synthesis_metadata', {})
                papers_count = synth_meta.get('papers_count', 0)
                avg_year = synth_meta.get('avg_year', 'N/A')
                status = synth_meta.get('status', 'unknown')

                col_meta1, col_meta2, col_meta3 = st.columns(3)
                with col_meta1:
                    st.caption(f"ğŸ“Š Dá»±a trÃªn {papers_count} bÃ i bÃ¡o cháº¥t lÆ°á»£ng cao")
                with col_meta2:
                    if isinstance(avg_year, (int, float)):
                        st.caption(f"ğŸ“… NÄƒm TB: {avg_year:.1f}")
                    else:
                        st.caption(f"ğŸ“… NÄƒm TB: {avg_year}")
                with col_meta3:
                    status_icon = "âœ…" if status == "success" else "âš ï¸"
                    st.caption(f"{status_icon} Status: {status}")

        st.markdown("---")

        # === PHáº¦N 3: LÆ¯U Káº¾T QUáº¢ === (was PHáº¦N 2)
```

### 3. Update Article Tabs Section (Around line 542-547)

**FIND:**
```python
tab1, tab2, tab3, tab4 = st.tabs([
    f"ğŸŒ Táº¥t cáº£ ({len(articles)})",
    f"ğŸ”¬ PubMed ({len(pubmed_articles)})",
    f"ğŸ“š Scopus ({len(scopus_articles)})",
    f"ğŸŒ Semantic Scholar ({len(semantic_articles)})"
])
```

**REPLACE WITH:**
```python
# Get discarded articles
discarded_articles = final_state.get('discarded_articles', [])

tab1, tab2, tab3, tab4, tab_discarded = st.tabs([
    f"ğŸŒ Táº¥t cáº£ ({len(articles)})",
    f"ğŸ”¬ PubMed ({len(pubmed_articles)})",
    f"ğŸ“š Scopus ({len(scopus_articles)})",
    f"ğŸŒ Semantic Scholar ({len(semantic_articles)})",
    f"ğŸ—‘ï¸ Bá»‹ lá»c ({len(discarded_articles)})"  # NEW TAB
])
```

### 4. Add Discarded Tab Content (After tab4 content, around line 633)

**INSERT:**
```python
        with tab_discarded:
            if not discarded_articles:
                st.info("âœ… KhÃ´ng cÃ³ bÃ i bÃ¡o nÃ o bá»‹ lá»c - táº¥t cáº£ Ä‘á»u Ä‘áº¡t tiÃªu chuáº©n!")
            else:
                st.warning(f"âš ï¸ {len(discarded_articles)} bÃ i bÃ¡o khÃ´ng Ä‘á»§ Ä‘iá»ƒm (< 7/10)")
                st.caption("ğŸ’¡ Xem láº¡i cÃ¡c bÃ i nÃ y Ä‘á»ƒ kiá»ƒm tra xem AI cÃ³ lá»c nháº§m khÃ´ng")

                for i, article in enumerate(discarded_articles, 1):
                    with st.container():
                        # Title
                        title = article.get('title', 'N/A')
                        st.markdown(f"### {i}. {title}")

                        # Metadata row
                        col_disc1, col_disc2, col_disc3 = st.columns(3)

                        with col_disc1:
                            source = article.get('source', 'N/A')
                            year = article.get('year', 'N/A')
                            st.caption(f"**Nguá»“n:** {source} | **NÄƒm:** {year}")

                        with col_disc2:
                            score = article.get('relevance_score', 'N/A')
                            if isinstance(score, (int, float)):
                                st.caption(f"**â­ Äiá»ƒm:** {score}/10")
                            else:
                                st.caption(f"**â­ Äiá»ƒm:** {score}")

                        with col_disc3:
                            # Link to paper
                            link = article.get('link', '#')
                            if link != '#':
                                st.markdown(f"[ğŸ”— Xem bÃ i bÃ¡o]({link})")

                        # AI Reasoning - why was it discarded?
                        with st.expander("ğŸ¤– Táº¡i sao bá»‹ lá»c?"):
                            reasoning = article.get('discard_reason') or article.get('ai_reasoning', 'KhÃ´ng cÃ³ lÃ½ do')
                            st.write(reasoning)

                        # Abstract (if available)
                        if show_abstract and article.get('abstract', 'N/A') != 'N/A':
                            with st.expander("ğŸ“„ Xem tÃ³m táº¯t"):
                                st.markdown(article['abstract'])

                        st.markdown("---")
```

### 5. Update display_article() Function (Around line 549)

**ADD relevance score display to each article:**

Find the caption section (around line 571-579) and ADD:

```python
# After the existing caption parts, add:
if article.get('relevance_score') is not None:
    score = article.get('relevance_score')
    score_icon = "â­" if score >= 8 else "âœ¨" if score >= 7 else ""
    caption_parts.append(f"{score_icon}**AI Score:** {score}/10")
```

### 6. Update PHáº¦N 3 Section Numbers

Since we added synthesis as PHáº¦N 2, update:
- "PHáº¦N 3: LÆ¯U Káº¾T QUáº¢" â†’ Keep as is (was PHáº¦N 2)
- "PHáº¦N 3: CHIáº¾N LÆ¯á»¢C AI" â†’ Becomes "PHáº¦N 4: CHIáº¾N LÆ¯á»¢C AI"
- "PHáº¦N 4: WORKFLOW LOG" â†’ Becomes "PHáº¦N 5: WORKFLOW LOG"

## Summary of Changes

1. âœ… **Metrics**: 4 columns â†’ 5 columns with filter statistics
2. âœ… **NEW Section**: AI Literature Review synthesis display
3. âœ… **NEW Tab**: Discarded articles tab
4. âœ… **Enhanced Display**: Show relevance scores on articles
5. âœ… **Better UX**: Clear explanations of why papers were filtered

## Testing Checklist

After making these changes:

- [ ] Metrics display correctly with new filter statistics
- [ ] Synthesis section shows when papers are found
- [ ] Synthesis section handles no-papers case
- [ ] Discarded tab shows filtered papers with reasons
- [ ] Discarded tab shows empty state when no papers discarded
- [ ] Relevance scores display on kept articles
- [ ] All tabs work correctly
- [ ] No layout issues or overlapping content

## Notes

- The synthesis will only show if `synthesis_summary` exists in state
- Discarded tab will be empty if all papers passed (score >= 7)
- This is backward compatible - if old state without new fields, it gracefully handles missing data
