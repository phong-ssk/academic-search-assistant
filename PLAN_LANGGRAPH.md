# ğŸ§  Plan: LangGraph Orchestration cho Academic Search

## ğŸ¯ Má»¥c TiÃªu

XÃ¢y dá»±ng `app_langgraph.py` sá»­ dá»¥ng LangGraph Ä‘á»ƒ tá»± Ä‘á»™ng Ä‘iá»u phá»‘i quy trÃ¬nh tÃ¬m kiáº¿m thÃ´ng minh, thay tháº¿ logic Ä‘Æ¡n giáº£n hiá»‡n táº¡i báº±ng AI agent cÃ³ kháº£ nÄƒng:

1. **PhÃ¢n tÃ­ch yÃªu cáº§u** cá»§a ngÆ°á»i dÃ¹ng
2. **Quyáº¿t Ä‘á»‹nh chiáº¿n lÆ°á»£c** tÃ¬m kiáº¿m (nguá»“n nÃ o, query nÃ o)
3. **Äiá»u phá»‘i song song** cÃ¡c API
4. **Tá»•ng há»£p & Ä‘Ã¡nh giÃ¡** káº¿t quáº£
5. **Tá»± Ä‘á»™ng tá»‘i Æ°u** náº¿u káº¿t quáº£ khÃ´ng Ä‘á»§

---

## ğŸ—ï¸ Kiáº¿n TrÃºc LangGraph

### Graph Structure

```
                    START
                      â†“
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  ANALYZE_QUERY  â”‚ â† PhÃ¢n tÃ­ch yÃªu cáº§u ngÆ°á»i dÃ¹ng
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  PLAN_STRATEGY  â”‚ â† AI quyáº¿t Ä‘á»‹nh:
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   - Nguá»“n nÃ o? (PubMed/Scopus/Semantic)
                      â†“           - Query EN/VN nhÆ° tháº¿ nÃ o?
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   - Bá»™ lá»c gÃ¬? (nÄƒm, sá»‘ lÆ°á»£ng)
            â”‚ OPTIMIZE_QUERIESâ”‚ â† Tá»‘i Æ°u query cho tá»«ng nguá»“n
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  EXECUTE_SEARCH â”‚ â† Gá»i API song song
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   (PubMed + Scopus + Semantic)
                      â†“
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ EVALUATE_RESULTSâ”‚ â† ÄÃ¡nh giÃ¡ cháº¥t lÆ°á»£ng káº¿t quáº£
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
                 â”Œâ”€â”€â”€â”€â”€â”
                 â”‚ OK? â”‚
                 â””â”€â”€â”€â”€â”€â”˜
                 â†™     â†˜
              YES       NO
               â†“         â†“
            â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚END â”‚  â”‚REFINE_QUERY â”‚ â†’ quay láº¡i OPTIMIZE_QUERIES
            â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ State Schema

```python
from typing import TypedDict, List, Dict, Optional
from langgraph.graph import StateGraph

class SearchState(TypedDict):
    # Input
    user_query: str
    user_preferences: Dict  # {max_results, year_range, sources}
    
    # Analysis
    query_analysis: Dict  # {intent, topic, language, complexity}
    
    # Planning
    search_strategy: Dict  # {
    #   sources: List[str],
    #   queries: {en: str, vn: str},
    #   filters: {...},
    #   priority: str
    # }
    
    # Execution
    search_results: Dict  # {source: [articles]}
    
    # Evaluation
    quality_score: float
    needs_refinement: bool
    refinement_reason: str
    
    # Output
    final_results: List[Dict]
    metadata: Dict
```

---

## ğŸ”§ Nodes (Chá»©c NÄƒng Tá»«ng BÆ°á»›c)

### 1. ANALYZE_QUERY
**Input:** `user_query`, `user_preferences`  
**Output:** `query_analysis`

**Logic:**
```python
def analyze_query(state: SearchState) -> SearchState:
    """
    DÃ¹ng Gemini phÃ¢n tÃ­ch:
    - Chá»§ Ä‘á»: Y há»c, Ká»¹ thuáº­t, Khoa há»c xÃ£ há»™i?
    - Ã Ä‘á»‹nh: TÃ¬m review? RCT? Case study?
    - NgÃ´n ngá»¯: Tiáº¿ng Viá»‡t hay Anh?
    - Äá»™ phá»©c táº¡p: ÄÆ¡n giáº£n/Phá»©c táº¡p/ChuyÃªn sÃ¢u
    """
    prompt = f"""
    PhÃ¢n tÃ­ch yÃªu cáº§u tÃ¬m kiáº¿m sau:
    "{state['user_query']}"
    
    Tráº£ vá» JSON:
    {{
        "topic": "medical/engineering/social/...",
        "intent": "review/rct/case_study/general",
        "language": "vi/en/mixed",
        "complexity": "simple/medium/complex",
        "keywords": ["key1", "key2", ...],
        "mesh_terms": ["term1", "term2", ...] # náº¿u lÃ  y há»c
    }}
    """
    analysis = gemini.generate(prompt, json_mode=True)
    state["query_analysis"] = analysis
    return state
```

---

### 2. PLAN_STRATEGY
**Input:** `query_analysis`, `user_preferences`  
**Output:** `search_strategy`

**Logic:**
```python
def plan_strategy(state: SearchState) -> SearchState:
    """
    Quyáº¿t Ä‘á»‹nh chiáº¿n lÆ°á»£c dá»±a trÃªn phÃ¢n tÃ­ch:
    
    Rules:
    - Náº¿u topic="medical" â†’ Æ¯u tiÃªn PubMed
    - Náº¿u topic="engineering" â†’ Æ¯u tiÃªn Scopus
    - Náº¿u language="vi" â†’ Báº¯t buá»™c cÃ³ Semantic Scholar
    - Náº¿u intent="review" â†’ TÃ¬m nhiá»u nguá»“n, filter nÄƒm gáº§n
    - Náº¿u complexity="complex" â†’ DÃ¹ng advanced query vá»›i Boolean
    """
    
    analysis = state["query_analysis"]
    
    # AI-based decision
    prompt = f"""
    Dá»±a trÃªn phÃ¢n tÃ­ch:
    {json.dumps(analysis, indent=2)}
    
    NgÆ°á»i dÃ¹ng muá»‘n tÃ¬m: {state['user_preferences']}
    
    HÃ£y Ä‘á» xuáº¥t chiáº¿n lÆ°á»£c tÃ¬m kiáº¿m tá»‘i Æ°u:
    {{
        "sources": ["PubMed", "Scopus", "Semantic Scholar"],
        "source_priority": "PubMed > Scopus > Semantic",
        "parallel_search": true,
        "filters": {{
            "year_range": [2020, 2025],
            "max_results_per_source": 30
        }},
        "reason": "Giáº£i thÃ­ch táº¡i sao chá»n chiáº¿n lÆ°á»£c nÃ y"
    }}
    """
    
    strategy = gemini.generate(prompt, json_mode=True)
    state["search_strategy"] = strategy
    return state
```

---

### 3. OPTIMIZE_QUERIES
**Input:** `user_query`, `query_analysis`, `search_strategy`  
**Output:** `search_strategy` (updated with optimized queries)

**Logic:**
```python
def optimize_queries(state: SearchState) -> SearchState:
    """
    Tá»‘i Æ°u query cho Tá»ªNG nguá»“n riÃªng biá»‡t
    """
    analysis = state["query_analysis"]
    strategy = state["search_strategy"]
    
    optimized = {}
    
    # PubMed: MeSH terms + Boolean
    if "PubMed" in strategy["sources"]:
        prompt_pubmed = f"""
        Táº¡o PubMed query tá»«: "{state['user_query']}"
        
        YÃªu cáº§u:
        - DÃ¹ng MeSH terms: {analysis.get('mesh_terms', [])}
        - DÃ¹ng Boolean operators (AND, OR, NOT)
        - Format: "term1[MeSH] AND (term2 OR term3)"
        
        Tráº£ vá» query duy nháº¥t (khÃ´ng giáº£i thÃ­ch):
        """
        optimized["pubmed"] = gemini.generate(prompt_pubmed).strip()
    
    # Scopus: Scopus syntax
    if "Scopus" in strategy["sources"]:
        prompt_scopus = f"""
        Táº¡o Scopus query tá»«: "{state['user_query']}"
        
        DÃ¹ng Scopus syntax:
        - TITLE-ABS-KEY()
        - AND, OR, AND NOT
        
        VÃ­ dá»¥: TITLE-ABS-KEY("machine learning" AND "healthcare")
        
        Tráº£ vá» query:
        """
        optimized["scopus"] = gemini.generate(prompt_scopus).strip()
    
    # Semantic Scholar: Tiáº¿ng Viá»‡t hoáº·c Anh tá»± nhiÃªn
    if "Semantic Scholar" in strategy["sources"]:
        if analysis["language"] == "vi":
            # Giá»¯ nguyÃªn tiáº¿ng Viá»‡t hoáº·c cáº£i thiá»‡n
            optimized["semantic"] = state["user_query"]
        else:
            # Tá»‘i Æ°u tiáº¿ng Anh
            prompt_semantic = f"""
            Cáº£i thiá»‡n query cho Semantic Scholar: "{state['user_query']}"
            
            YÃªu cáº§u: Ngáº¯n gá»n, dá»… hiá»ƒu, ngÃ´n ngá»¯ tá»± nhiÃªn
            
            Tráº£ vá» query:
            """
            optimized["semantic"] = gemini.generate(prompt_semantic).strip()
    
    state["search_strategy"]["optimized_queries"] = optimized
    return state
```

---

### 4. EXECUTE_SEARCH
**Input:** `search_strategy`  
**Output:** `search_results`

**Logic:**
```python
import asyncio

async def execute_search(state: SearchState) -> SearchState:
    """
    Thá»±c thi tÃ¬m kiáº¿m SONG SONG trÃªn cÃ¡c nguá»“n
    """
    strategy = state["search_strategy"]
    queries = strategy["optimized_queries"]
    filters = strategy["filters"]
    
    async def search_pubmed():
        if "pubmed" in queries:
            return await pubmed_api.search_async(
                query=queries["pubmed"],
                max_results=filters["max_results_per_source"],
                year_start=filters["year_range"][0],
                year_end=filters["year_range"][1]
            )
        return []
    
    async def search_scopus():
        if "scopus" in queries:
            return await scopus_api.search_async(
                query=queries["scopus"],
                max_results=filters["max_results_per_source"],
                year_start=filters["year_range"][0],
                year_end=filters["year_range"][1]
            )
        return []
    
    async def search_semantic():
        if "semantic" in queries:
            return await semantic_api.search_async(
                query=queries["semantic"],
                max_results=filters["max_results_per_source"],
                year_start=filters["year_range"][0],
                year_end=filters["year_range"][1]
            )
        return []
    
    # Parallel execution
    results = await asyncio.gather(
        search_pubmed(),
        search_scopus(),
        search_semantic()
    )
    
    state["search_results"] = {
        "PubMed": results[0],
        "Scopus": results[1],
        "Semantic Scholar": results[2]
    }
    
    return state
```

---

### 5. EVALUATE_RESULTS
**Input:** `search_results`, `query_analysis`  
**Output:** `quality_score`, `needs_refinement`, `final_results`

**Logic:**
```python
def evaluate_results(state: SearchState) -> SearchState:
    """
    ÄÃ¡nh giÃ¡ cháº¥t lÆ°á»£ng káº¿t quáº£ & quyáº¿t Ä‘á»‹nh cÃ³ cáº§n refine khÃ´ng
    """
    results = state["search_results"]
    total_count = sum(len(articles) for articles in results.values())
    
    # Basic checks
    if total_count == 0:
        state["needs_refinement"] = True
        state["refinement_reason"] = "No results found"
        state["quality_score"] = 0.0
        return state
    
    # AI-based evaluation
    prompt = f"""
    ÄÃ¡nh giÃ¡ cháº¥t lÆ°á»£ng káº¿t quáº£ tÃ¬m kiáº¿m:
    
    Query gá»‘c: "{state['user_query']}"
    PhÃ¢n tÃ­ch: {state['query_analysis']}
    
    Káº¿t quáº£:
    - PubMed: {len(results.get('PubMed', []))} bÃ i
    - Scopus: {len(results.get('Scopus', []))} bÃ i
    - Semantic Scholar: {len(results.get('Semantic Scholar', []))} bÃ i
    
    Top 3 titles tá»« má»—i nguá»“n:
    {json.dumps([r['title'] for r in results.get('PubMed', [])[:3]])}
    {json.dumps([r['title'] for r in results.get('Scopus', [])[:3]])}
    {json.dumps([r['title'] for r in results.get('Semantic Scholar', [])[:3]])}
    
    ÄÃ¡nh giÃ¡:
    {{
        "quality_score": 0.0-1.0,  # 0=khÃ´ng liÃªn quan, 1=ráº¥t liÃªn quan
        "needs_refinement": true/false,
        "reason": "Giáº£i thÃ­ch",
        "suggestions": "Gá»£i Ã½ cáº£i thiá»‡n (náº¿u cáº§n)"
    }}
    """
    
    evaluation = gemini.generate(prompt, json_mode=True)
    
    state["quality_score"] = evaluation["quality_score"]
    state["needs_refinement"] = evaluation["needs_refinement"]
    state["refinement_reason"] = evaluation.get("reason", "")
    
    # Merge and deduplicate results
    all_articles = []
    seen_dois = set()
    
    for source, articles in results.items():
        for article in articles:
            doi = article.get("doi", "")
            if doi and doi != "N/A":
                if doi not in seen_dois:
                    seen_dois.add(doi)
                    all_articles.append(article)
            else:
                # No DOI, add anyway but may have duplicates
                all_articles.append(article)
    
    state["final_results"] = all_articles
    
    return state
```

---

### 6. REFINE_QUERY
**Input:** `refinement_reason`, `search_strategy`  
**Output:** `search_strategy` (updated)

**Logic:**
```python
def refine_query(state: SearchState) -> SearchState:
    """
    Tá»± Ä‘á»™ng cáº£i thiá»‡n query dá»±a trÃªn lÃ½ do refinement
    """
    reason = state["refinement_reason"]
    current_strategy = state["search_strategy"]
    
    prompt = f"""
    Káº¿t quáº£ tÃ¬m kiáº¿m khÃ´ng Ä‘áº¡t yÃªu cáº§u.
    
    LÃ½ do: {reason}
    Chiáº¿n lÆ°á»£c hiá»‡n táº¡i: {json.dumps(current_strategy, indent=2)}
    
    HÃ£y Ä‘á» xuáº¥t cáº£i thiá»‡n:
    {{
        "new_queries": {{
            "pubmed": "...",
            "scopus": "...",
            "semantic": "..."
        }},
        "adjust_filters": {{
            "year_range": [2015, 2025],  # Má»Ÿ rá»™ng pháº¡m vi
            "max_results_per_source": 50  # TÄƒng sá»‘ lÆ°á»£ng
        }},
        "explanation": "Giáº£i thÃ­ch thay Ä‘á»•i"
    }}
    """
    
    refinement = gemini.generate(prompt, json_mode=True)
    
    # Update strategy
    state["search_strategy"]["optimized_queries"] = refinement["new_queries"]
    state["search_strategy"]["filters"] = refinement["adjust_filters"]
    
    return state
```

---

## ğŸ”„ Conditional Edges

```python
def should_refine(state: SearchState) -> str:
    """
    Quyáº¿t Ä‘á»‹nh cÃ³ nÃªn refine query khÃ´ng
    
    Max 2 láº§n refinement Ä‘á»ƒ trÃ¡nh vÃ²ng láº·p vÃ´ háº¡n
    """
    if not state["needs_refinement"]:
        return "END"
    
    # Check refinement count
    refinement_count = state.get("refinement_count", 0)
    if refinement_count >= 2:
        # ÄÃ£ refine 2 láº§n, dá»«ng láº¡i
        return "END"
    
    state["refinement_count"] = refinement_count + 1
    return "REFINE"
```

---

## ğŸ› ï¸ Implementation Plan

### Phase 1: Setup
```bash
pip install langgraph langchain-google-genai langchain-core
```

### Phase 2: File Structure
```
backend/
â”œâ”€â”€ langgraph_orchestrator.py  # LangGraph logic
â”œâ”€â”€ nodes/
â”‚   â”œâ”€â”€ analyze.py
â”‚   â”œâ”€â”€ plan.py
â”‚   â”œâ”€â”€ optimize.py
â”‚   â”œâ”€â”€ execute.py
â”‚   â”œâ”€â”€ evaluate.py
â”‚   â””â”€â”€ refine.py
â””â”€â”€ async_apis.py  # Async wrappers for PubMed/Scopus/Semantic
```

### Phase 3: Build Graph
```python
from langgraph.graph import StateGraph, END

def build_search_graph():
    workflow = StateGraph(SearchState)
    
    # Add nodes
    workflow.add_node("analyze_query", analyze_query)
    workflow.add_node("plan_strategy", plan_strategy)
    workflow.add_node("optimize_queries", optimize_queries)
    workflow.add_node("execute_search", execute_search)
    workflow.add_node("evaluate_results", evaluate_results)
    workflow.add_node("refine_query", refine_query)
    
    # Add edges
    workflow.set_entry_point("analyze_query")
    workflow.add_edge("analyze_query", "plan_strategy")
    workflow.add_edge("plan_strategy", "optimize_queries")
    workflow.add_edge("optimize_queries", "execute_search")
    workflow.add_edge("execute_search", "evaluate_results")
    
    # Conditional edge
    workflow.add_conditional_edges(
        "evaluate_results",
        should_refine,
        {
            "END": END,
            "REFINE": "refine_query"
        }
    )
    workflow.add_edge("refine_query", "optimize_queries")
    
    return workflow.compile()
```

### Phase 4: Streamlit Integration (app_langgraph.py)
```python
import streamlit as st
from backend.langgraph_orchestrator import build_search_graph

# Build graph once
graph = build_search_graph()

# UI
query = st.text_area("Nháº­p yÃªu cáº§u tÃ¬m kiáº¿m...")

if st.button("ğŸš€ TÃ¬m kiáº¿m thÃ´ng minh"):
    initial_state = {
        "user_query": query,
        "user_preferences": {
            "max_results": max_results,
            "year_range": year_range,
            "sources": selected_sources
        }
    }
    
    # Execute graph
    with st.spinner("AI Ä‘ang phÃ¢n tÃ­ch vÃ  tÃ¬m kiáº¿m..."):
        final_state = graph.invoke(initial_state)
    
    # Display results
    st.success(f"TÃ¬m tháº¥y {len(final_state['final_results'])} bÃ i bÃ¡o")
    st.info(f"Quality Score: {final_state['quality_score']:.2f}")
    
    # Show strategy used
    with st.expander("ğŸ§  Chiáº¿n lÆ°á»£c AI Ä‘Ã£ dÃ¹ng"):
        st.json(final_state["search_strategy"])
    
    # Display articles
    for article in final_state["final_results"]:
        display_article(article)
```

---

## ğŸ“Š Advantages cá»§a LangGraph Approach

### So vá»›i App hiá»‡n táº¡i:

| Feature | App hiá»‡n táº¡i | App LangGraph |
|---------|-------------|---------------|
| **Query optimization** | Manual (user chá»n) | Auto (AI quyáº¿t Ä‘á»‹nh) |
| **Source selection** | Fixed | Dynamic (dá»±a trÃªn topic) |
| **Error handling** | Simple | Self-healing (auto refine) |
| **Result quality** | No validation | AI evaluation |
| **Parallel execution** | Sequential | True async parallel |
| **Adaptability** | Static | Self-improving |
| **User experience** | Multi-step | One-click |

---

## ğŸ¯ Use Cases

### Case 1: Medical Research
```
Input: "Äiá»u trá»‹ ung thÆ° phá»•i giai Ä‘oáº¡n muá»™n"

LangGraph Flow:
1. Analyze â†’ topic=medical, intent=treatment
2. Plan â†’ Priority: PubMed > Semantic > Scopus
3. Optimize â†’ PubMed: MeSH terms + RCT filter
4. Execute â†’ 45 results
5. Evaluate â†’ Score 0.85 â†’ Good â†’ END
```

### Case 2: Engineering + Vietnamese
```
Input: "Machine learning trong dá»± bÃ¡o thá»i tiáº¿t"

LangGraph Flow:
1. Analyze â†’ topic=engineering, language=vi
2. Plan â†’ Semantic Scholar (vÃ¬ tiáº¿ng Viá»‡t) + Scopus
3. Optimize â†’ Keep Vietnamese for Semantic
4. Execute â†’ 12 results
5. Evaluate â†’ Score 0.45 â†’ Low â†’ REFINE
6. Refine â†’ Expand to "machine learning weather forecasting climate"
7. Execute â†’ 78 results
8. Evaluate â†’ Score 0.82 â†’ Good â†’ END
```

---

## ğŸš€ Next Steps

1. **Phase 1 (Week 1):** 
   - Setup LangGraph
   - Build basic nodes (analyze, plan, optimize)
   - Test with mock data

2. **Phase 2 (Week 2):**
   - Implement async API wrappers
   - Build execute & evaluate nodes
   - Test end-to-end flow

3. **Phase 3 (Week 3):**
   - Add refinement loop
   - Build Streamlit UI (app_langgraph.py)
   - A/B test vs current app

4. **Phase 4 (Week 4):**
   - Fine-tune prompts
   - Add caching & optimization
   - Deploy & monitor

---

## ğŸ’¡ Advanced Features (Future)

1. **Multi-agent collaboration:**
   - Specialist agents cho tá»«ng nguá»“n (PubMedAgent, ScopusAgent)
   - Coordinator agent Ä‘iá»u phá»‘i

2. **Learning from user feedback:**
   - Thu tháº­p user ratings
   - Fine-tune strategy prompts

3. **Citation network analysis:**
   - TÃ¬m papers liÃªn quan qua citations
   - Build knowledge graph

4. **Multi-turn conversation:**
   - User há»i thÃªm: "TÃ¬m bÃ i má»›i hÆ¡n"
   - Agent nhá»› context vÃ  refine

---

**TÃ i liá»‡u tham kháº£o:**
- LangGraph Docs: https://langchain-ai.github.io/langgraph/
- Multi-agent patterns: https://langchain-ai.github.io/langgraph/tutorials/multi_agent/
